fullnameOverride: "prometheus"

defaultRules:
  create: true
  rules:
    alertmanager: true
    etcd: true
    configReloaders: true
    general: true
    k8sContainerCpuUsageSecondsTotal: true
    k8sContainerMemoryCache: true
    k8sContainerMemoryRss: true
    k8sContainerMemorySwap: true
    k8sContainerResource: true
    k8sContainerMemoryWorkingSetBytes: true
    k8sPodOwner: true
    kubeApiserverAvailability: true
    kubeApiserverBurnrate: true
    kubeApiserverHistogram: true
    kubeApiserverSlos: true
    kubeControllerManager: true
    kubelet: true
    kubeProxy: true
    kubePrometheusGeneral: true
    kubePrometheusNodeRecording: true
    kubernetesApps: true
    kubernetesResources: true
    kubernetesStorage: true
    kubernetesSystem: true
    kubeSchedulerAlerting: true
    kubeSchedulerRecording: true
    kubeStateMetrics: true
    network: true
    node: true
    nodeExporterAlerting: true
    nodeExporterRecording: true
    prometheus: true
    prometheusOperator: true
    windows: false

  appNamespacesTarget: ".*"
  keepFiringFor: ""
  labels: {}
  annotations: {}
  additionalRuleLabels: {}
  additionalRuleAnnotations: {}

  additionalRuleGroupLabels:
    alertmanager: {}
    etcd: {}
    configReloaders: {}
    general: {}
    k8sContainerCpuUsageSecondsTotal: {}
    k8sContainerMemoryCache: {}
    k8sContainerMemoryRss: {}
    k8sContainerMemorySwap: {}
    k8sContainerResource: {}
    k8sPodOwner: {}
    kubeApiserverAvailability: {}
    kubeApiserverBurnrate: {}
    kubeApiserverHistogram: {}
    kubeApiserverSlos: {}
    kubeControllerManager: {}
    kubelet: {}
    kubeProxy: {}
    kubePrometheusGeneral: {}
    kubePrometheusNodeRecording: {}
    kubernetesApps: {}
    kubernetesResources: {}
    kubernetesStorage: {}
    kubernetesSystem: {}
    kubeSchedulerAlerting: {}
    kubeSchedulerRecording: {}
    kubeStateMetrics: {}
    network: {}
    node: {}
    nodeExporterAlerting: {}
    nodeExporterRecording: {}
    prometheus: {}
    prometheusOperator: {}

  ## Additional annotations for specific PrometheusRule alerts groups
  additionalRuleGroupAnnotations:
    alertmanager: {}
    etcd: {}
    configReloaders: {}
    general: {}
    k8sContainerCpuUsageSecondsTotal: {}
    k8sContainerMemoryCache: {}
    k8sContainerMemoryRss: {}
    k8sContainerMemorySwap: {}
    k8sContainerResource: {}
    k8sPodOwner: {}
    kubeApiserverAvailability: {}
    kubeApiserverBurnrate: {}
    kubeApiserverHistogram: {}
    kubeApiserverSlos: {}
    kubeControllerManager: {}
    kubelet: {}
    kubeProxy: {}
    kubePrometheusGeneral: {}
    kubePrometheusNodeRecording: {}
    kubernetesApps: {}
    kubernetesResources: {}
    kubernetesStorage: {}
    kubernetesSystem: {}
    kubeSchedulerAlerting: {}
    kubeSchedulerRecording: {}
    kubeStateMetrics: {}
    network: {}
    node: {}
    nodeExporterAlerting: {}
    nodeExporterRecording: {}
    prometheus: {}
    prometheusOperator: {}

  additionalAggregationLabels: []
  runbookUrl: "https://runbooks.prometheus-operator.dev/runbooks"
  disabled: {}
additionalPrometheusRulesMap: {}
global:
  rbac:
    create: true
    createAggregateClusterRoles: false
    pspEnabled: false
    pspAnnotations: {}
  imageRegistry: ""
  imagePullSecrets: []

windowsMonitoring:
  enabled: false

prometheus-windows-exporter:
  prometheus:
    monitor:
      enabled: true
      jobLabel: jobLabel
  releaseLabel: true
  podLabels:
    jobLabel: windows-exporter
  config: |-
    collectors:
      enabled: '[defaults],memory,container'

alertmanager:
  fullnameOverride: alertmanager
  enabled: true
  annotations: {}
  apiVersion: v2
  enableFeatures: []
  serviceAccount:
    create: true
    name: ""
    annotations: {}
    automountServiceAccountToken: true
  podDisruptionBudget:
    enabled: false
    minAvailable: 1
    maxUnavailable: ""
  config:
    global:
      resolve_timeout: 5m
    inhibit_rules:
      - source_matchers:
          - 'severity = critical'
        target_matchers:
          - 'severity =~ warning|info'
        equal:
          - 'namespace'
          - 'alertname'
      - source_matchers:
          - 'severity = warning'
        target_matchers:
          - 'severity = info'
        equal:
          - 'namespace'
          - 'alertname'
      - source_matchers:
          - 'alertname = InfoInhibitor'
        target_matchers:
          - 'severity = info'
        equal:
          - 'namespace'
      - target_matchers:
          - 'alertname = InfoInhibitor'
    route:
      group_by: ['namespace']
      group_wait: 30s
      group_interval: 5m
      repeat_interval: 12h
      receiver: 'null'
      routes:
      - receiver: 'null'
        matchers:
          - alertname = "Watchdog"
    receivers:
    - name: 'null'
    templates:
    - '/etc/alertmanager/config/*.tmpl'
  stringConfig: ""
  tplConfig: false
  templateFiles: {}

  ingress:
    enabled: false

  service:
    annotations: {}
    labels: {}
    clusterIP: ""
    ipDualStack:
      enabled: false
      ipFamilies: ["IPv6", "IPv4"]
      ipFamilyPolicy: "PreferDualStack"
    port: 9093
    targetPort: 9093
    nodePort: 30903
    additionalPorts: []
    externalIPs: []
    loadBalancerIP: ""
    loadBalancerSourceRanges: []
    externalTrafficPolicy: Cluster
    sessionAffinity: None
    sessionAffinityConfig:
      clientIP:
        timeoutSeconds: 10800
    type: ClusterIP
  servicePerReplica:
    enabled: false
    annotations: {}
    port: 9093
    targetPort: 9093
    nodePort: 30904
    loadBalancerSourceRanges: []
    externalTrafficPolicy: Cluster
    type: ClusterIP
  serviceMonitor:
    selfMonitor: true
    interval: ""
    additionalLabels: {}
    sampleLimit: 0
    targetLimit: 0
    labelLimit: 0
    labelNameLengthLimit: 0
    labelValueLengthLimit: 0
    proxyUrl: ""
    scheme: ""
    enableHttp2: true
    tlsConfig: {}
    bearerTokenFile:
    metricRelabelings: []
    relabelings: []
    additionalEndpoints: []
  alertmanagerSpec:
    podMetadata: {}
    useExistingSecret: false
    secrets: []
    automountServiceAccountToken: true
    configMaps: []
    web: {}
    alertmanagerConfigSelector: {}
    alertmanagerConfigNamespaceSelector: {}
    alertmanagerConfiguration: {}
    alertmanagerConfigMatcherStrategy: {}
    logFormat: logfmt
    logLevel: info
    replicas: 1
    retention: 120h
    storage:
      volumeClaimTemplate:
        spec:
          accessModes:
          - ReadWriteOnce
          storageClassName: longhorn-data
          resources:
            requests:
              storage: 4Gi
          volumeName: pv-kube-alertmanager # must reference Persistent Volume
    externalUrl:
    routePrefix: /
    scheme: ""
    tlsConfig: {}
    paused: false
    nodeSelector:
      kubernetes.io/hostname: dev-k3s-master-0
    resources: {}
    podAntiAffinity: ""
    podAntiAffinityTopologyKey: kubernetes.io/hostname
    affinity: {}
    tolerations: []
    topologySpreadConstraints: []
    securityContext:
      runAsGroup: 2000
      runAsNonRoot: true
      runAsUser: 1000
      fsGroup: 2000
      seccompProfile:
        type: RuntimeDefault
    listenLocal: false
    containers: []
    volumes: []
    volumeMounts: []
    initContainers: []
    priorityClassName: ""
    additionalPeers: []
    portName: "http-web"
    clusterAdvertiseAddress: false
    clusterGossipInterval: ""
    clusterPeerTimeout: ""
    clusterPushpullInterval: ""
    forceEnableClusterMode: false
    minReadySeconds: 0
    additionalConfig: {}
    additionalConfigString: ""
  extraSecret:
    annotations: {}
    data: {}

grafana:
  enabled: true
  fullnameOverride: grafana
  namespaceOverride: ""
  forceDeployDatasources: false
  forceDeployDashboards: false
  defaultDashboardsEnabled: true
  defaultDashboardsTimezone: cet
  defaultDashboardsEditable: true

  admin:
    existingSecret: grafana-admin-secret
    userKey: username
    passwordKey: password

  rbac:
    pspEnabled: false

  ingress:
    enabled: false

  persistence:
    enabled: true
    existingClaim: storage-grafana-0
    extraPvcLabels: {}

  serviceAccount:
    create: true
    autoMount: true

  dashboardProviders:
    dashboardproviders.yaml:
      apiVersion: 1
      providers:
        - name: "devices"
          orgId: 1
          folder: "Devices"
          type: file
          disableDeletion: false
          editable: true
          options:
            path: /var/lib/grafana/dashboards/device

        - name: "extra"
          orgId: 1
          folder: "Extra"
          type: file
          disableDeletion: false
          editable: true
          allowUiUpdates: true
          options:
            path: /var/lib/grafana/dashboards/extra

        - name: "freqtrade"
          orgId: 1
          folder: "Freqtrade"
          type: file
          disableDeletion: false
          editable: true
          options:
            path: /var/lib/grafana/dashboards/freqtrade

        - name: "kubernetes"
          orgId: 1
          folder: "Kubernetes"
          type: file
          disableDeletion: false
          editable: true
          options:
            path: /var/lib/grafana/dashboards/kubernetes

        - name: "network"
          orgId: 1
          folder: "Network"
          type: file
          disableDeletion: false
          editable: true
          options:
            path: /var/lib/grafana/dashboards/network

        - name: "storage"
          orgId: 1
          folder: "Storage"
          type: file
          disableDeletion: false
          editable: true
          allowUiUpdates: true
          options:
            path: /var/lib/grafana/dashboards/storage

  ## Configure grafana dashboard
  dashboards:
    devices:
      prometheus-pve-exporter:
        gnetId: 10347
        revision: 5
        datasource:
        - name: DS_PROMETHEUS
          value: Prometheus
      blackbox-exporter-overview:
        gnetId: 5345
        datasource: Prometheus

    extra:
      argocd-overview:
        gnetId: 14584
        datasource: Prometheus
      authentik:
        gnetId: 14837
        datasource: Prometheus
      cert-manager:
        gnetId: 20842
        datasource:
        - name: DS_PROMETHEUS
          value: Prometheus
      external-dns-overview:
        gnetId: 15038
        datasource: Prometheus

    freqtrade:
      freqtrade:
        gnetId: 14632
        datasource: Prometheus

    kubernetes:
      k8s-addons-prometheus:
        gnetId: 19105
        datasource: Prometheus
      k8s-addons-trivy-operator:
        gnetId: 16337
        datasource: Prometheus
      k8s-system-api-server:
        gnetId: 15761
        datasource: Prometheus
      k8s-system-coredns:
        gnetId: 15762
        datasource: Prometheus
      k8s-views-global:
        gnetId: 15757
        datasource: Prometheus
      k8s-views-namespaces:
        gnetId: 15758
        datasource: Prometheus
      k8s-views-nodes:
        gnetId: 15759
        datasource: Prometheus
      k8s-views-pods:
        gnetId: 15760
        datasource: Prometheus

    network:
      mikrotik:
        gnetId: 13679
        revision: 22
        datasource:
        - name: DS_PROMETHEUS
          value: Prometheus
      mikrotik2:
        gnetId: 13679
        revision: 21
        datasource:
        - name: DS_PROMETHEUS
          value: Prometheus
      mikrotik3:
        gnetId: 13679
        revision: 20
        datasource:
        - name: DS_PROMETHEUS
          value: Prometheus
      traefik:
        gnetId: 17347
        revision: 8
        datasource:
        - name: DS_PROMETHEUS
          value: Prometheus
      traefik2:
        gnetId: 17346
        revision: 8
        datasource:
        - name: DS_PROMETHEUS
          value: Prometheus

    storage:
      minio-dashboard:
        gnetId: 13502
        revision: 26
        datasources:
        - name: DS_PROMETHEUS
          value: Prometheus
      minio-bucket:
        gnetId: 19237
        datasources:
        - name: DS_PROMETHEUS
          value: Prometheus
      longhorn:
        gnetId: 16888
        datasource:
        - name: DS_PROMETHEUS
          value: Prometheus

  sidecar:
    dashboards:
      enabled: true
      label: grafana_dashboard
      labelValue: "1"
      searchNamespace: ALL
      enableNewTablePanelSyntax: false
      annotations: {}
      multicluster:
        global:
          enabled: false
        etcd:
          enabled: false
      provider:
        name: sidecarProvider
        orgid: "1"
        folder: ""
        type: file
        disableDelete: false
        allowUiUpdates: true
        foldersFromFilesStructure: true

    datasources:
      enabled: true
      defaultDatasourceEnabled: true
      isDefaultDatasource: true
      name: Prometheus
      uid: prometheus
      annotations: {}
      httpMethod: POST
      createPrometheusReplicasDatasources: false
      label: grafana_datasource
      labelValue: "1"
      exemplarTraceIdDestinations:
        datasourceUid: tempo
        traceIdLabelName: trace_id
      alertmanager:
        enabled: true
        name: Alertmanager
        uid: alertmanager
        handleGrafanaManagedAlerts: false
        implementation: prometheus

  extraConfigmapMounts: []
  deleteDatasources: []

  additionalDataSources:
    - name: Loki
      type: loki
      url: http://loki-gateway.monitoring
    # More config at https://grafana.com/docs/grafana/latest/datasources/tempo/configure-tempo-data-source/
    - name: Tempo
      uid: tempo
      type: tempo
      access: proxy
      url: http://tempo.monitoring.svc:3100
      jsonData:
        tracesToMetrics:
          datasourceUid: 'prom'
          spanStartTimeShift: '1h'
          spanEndTimeShift: '-1h'
          tags: [{ key: 'service.name', value: 'service' }]
          queries:
            - name: 'latency'
              query: 'sum(rate(traces_spanmetrics_latency_bucket{$$__tags}[5m]))'
        serviceMap:
          datasourceUid: 'prometheus'
        nodeGraph:
          enabled: true
        search:
          hide: false
        traceQuery:
          timeShiftEnabled: true
          spanStartTimeShift: '1h'
          spanEndTimeShift: '-1h'

  service:
    portName: http-web
    ipFamilies: []
    ipFamilyPolicy: ""

  serviceMonitor:
    enabled: true
    path: "/metrics"
    labels: {}
    interval: ""
    scheme: http
    tlsConfig: {}
    scrapeTimeout: 30s
    relabelings: []

kubernetesServiceMonitors:
  enabled: true

kubeApiServer:
  enabled: true
  tlsConfig:
    serverName: kubernetes
    insecureSkipVerify: false
  serviceMonitor:
    interval: ""
    sampleLimit: 0
    targetLimit: 0
    labelLimit: 0
    labelNameLengthLimit: 0
    labelValueLengthLimit: 0
    proxyUrl: ""
    jobLabel: component
    selector:
      matchLabels:
        component: apiserver
        provider: kubernetes

    metricRelabelings:
      - action: drop
        regex: apiserver_request_duration_seconds_bucket;(0.15|0.2|0.3|0.35|0.4|0.45|0.6|0.7|0.8|0.9|1.25|1.5|1.75|2|3|3.5|4|4.5|6|7|8|9|15|25|40|50)
        sourceLabels:
          - __name__
          - le
    # - action: keep
    #   regex: 'kube_(daemonset|deployment|pod|namespace|node|statefulset).+'
    #   sourceLabels: [__name__]
    relabelings: []
    # - sourceLabels:
    #     - __meta_kubernetes_namespace
    #     - __meta_kubernetes_service_name
    #     - __meta_kubernetes_endpoint_port_name
    #   action: keep
    #   regex: default;kubernetes;https
    # - targetLabel: __address__
    #   replacement: kubernetes.default.svc:443

    ## Additional labels
    ##
    additionalLabels: {}
    #  foo: bar

## Component scraping the kubelet and kubelet-hosted cAdvisor
##
kubelet:
  enabled: true
  namespace: kube-system

  serviceMonitor:
    attachMetadata:
      node: false
    interval: ""
    honorLabels: true
    honorTimestamps: true
    sampleLimit: 0
    targetLimit: 0
    labelLimit: 0
    labelNameLengthLimit: 0
    labelValueLengthLimit: 0
    proxyUrl: ""
    https: true
    insecureSkipVerify: true

    cAdvisor: false
    probes: true
    resource: false
    resourcePath: "/metrics/resource"

    cAdvisorMetricRelabelings:
      - sourceLabels: [__name__]
        action: drop
        regex: 'container_cpu_(cfs_throttled_seconds_total|load_average_10s|system_seconds_total|user_seconds_total)'
      - sourceLabels: [__name__]
        action: drop
        regex: 'container_fs_(io_current|io_time_seconds_total|io_time_weighted_seconds_total|reads_merged_total|sector_reads_total|sector_writes_total|writes_merged_total)'
      - sourceLabels: [__name__]
        action: drop
        regex: 'container_memory_(mapped_file|swap)'
      - sourceLabels: [__name__]
        action: drop
        regex: 'container_(file_descriptors|tasks_state|threads_max)'
      - sourceLabels: [__name__]
        action: drop
        regex: 'container_spec.*'
      - sourceLabels: [id, pod]
        action: drop
        regex: '.+;'

    probesMetricRelabelings: []

    cAdvisorRelabelings:
      - action: replace
        sourceLabels: [__metrics_path__]
        targetLabel: metrics_path

    probesRelabelings:
      - action: replace
        sourceLabels: [__metrics_path__]
        targetLabel: metrics_path

    resourceRelabelings:
      - action: replace
        sourceLabels: [__metrics_path__]
        targetLabel: metrics_path

    metricRelabelings:
      - action: replace
        sourceLabels:
          - node
        targetLabel: instance

    relabelings:
      - action: replace
        sourceLabels: [__metrics_path__]
        targetLabel: metrics_path

    additionalLabels: {}

kubeControllerManager:
  enabled: true
  endpoints: []
  endpoints: # ips of servers 
    - 192.168.40.110

  service:
    enabled: true
    port: null
    targetPort: null
    ipDualStack:
      enabled: false
      ipFamilies: ["IPv6", "IPv4"]
      ipFamilyPolicy: "PreferDualStack"
    # selector:
    #   component: kube-controller-manager

  serviceMonitor:
    enabled: true
    ## Scrape interval. If not set, the Prometheus default scrape interval is used.
    ##
    interval: ""

    ## SampleLimit defines per-scrape limit on number of scraped samples that will be accepted.
    ##
    sampleLimit: 0

    ## TargetLimit defines a limit on the number of scraped targets that will be accepted.
    ##
    targetLimit: 0

    ## Per-scrape limit on number of labels that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.
    ##
    labelLimit: 0

    ## Per-scrape limit on length of labels name that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.
    ##
    labelNameLengthLimit: 0

    ## Per-scrape limit on length of labels value that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.
    ##
    labelValueLengthLimit: 0

    ## proxyUrl: URL of a proxy that should be used for scraping.
    ##
    proxyUrl: ""

    ## port: Name of the port the metrics will be scraped from
    ##
    port: http-metrics

    jobLabel: jobLabel
    selector: {}
    #  matchLabels:
    #    component: kube-controller-manager

    ## Enable scraping kube-controller-manager over https.
    ## Requires proper certs (not self-signed) and delegated authentication/authorization checks.
    ## If null or unset, the value is determined dynamically based on target Kubernetes version.
    ##
    https: null

    # Skip TLS certificate validation when scraping
    insecureSkipVerify: null

    # Name of the server to use when validating TLS certificate
    serverName: null

    ## MetricRelabelConfigs to apply to samples after scraping, but before ingestion.
    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#relabelconfig
    ##
    metricRelabelings: []
    # - action: keep
    #   regex: 'kube_(daemonset|deployment|pod|namespace|node|statefulset).+'
    #   sourceLabels: [__name__]

    ## RelabelConfigs to apply to samples before scraping
    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#relabelconfig
    ##
    relabelings: []
    # - sourceLabels: [__meta_kubernetes_pod_node_name]
    #   separator: ;
    #   regex: ^(.*)$
    #   targetLabel: nodename
    #   replacement: $1
    #   action: replace

    ## Additional labels
    ##
    additionalLabels: {}
    #  foo: bar

## Component scraping coreDns. Use either this or kubeDns
##
coreDns:
  enabled: true
  service:
    enabled: true
    port: 9153
    targetPort: 9153

    ipDualStack:
      enabled: false
      ipFamilies: ["IPv6", "IPv4"]
      ipFamilyPolicy: "PreferDualStack"
    # selector:
    #   k8s-app: kube-dns
  serviceMonitor:
    enabled: true
    interval: ""
    sampleLimit: 0
    targetLimit: 0
    labelLimit: 0
    labelNameLengthLimit: 0
    labelValueLengthLimit: 0
    proxyUrl: ""
    port: http-metrics

    jobLabel: jobLabel
    selector: {}
    metricRelabelings: []
    relabelings: []
    additionalLabels: {}

kubeDns:
  enabled: false
  service:
    dnsmasq:
      port: 10054
      targetPort: 10054
    skydns:
      port: 10055
      targetPort: 10055
    ipDualStack:
      enabled: false
      ipFamilies: ["IPv6", "IPv4"]
      ipFamilyPolicy: "PreferDualStack"
    # selector:
    #   k8s-app: kube-dns
  serviceMonitor:
    interval: ""
    sampleLimit: 0
    targetLimit: 0
    labelLimit: 0
    labelNameLengthLimit: 0
    labelValueLengthLimit: 0
    proxyUrl: ""

    jobLabel: jobLabel
    selector: {}
    metricRelabelings: []
    relabelings: []
    dnsmasqMetricRelabelings: []
    dnsmasqRelabelings: []
    additionalLabels: {}

kubeEtcd:
  enabled: true
  endpoints: # ips of servers
    - 192.168.40.110

  service:
    enabled: true
    port: 2381
    targetPort: 2381
    ipDualStack:
      enabled: false
      ipFamilies: ["IPv6", "IPv4"]
      ipFamilyPolicy: "PreferDualStack"

  serviceMonitor:
    enabled: true
    interval: ""
    sampleLimit: 0
    targetLimit: 0
    labelLimit: 0
    labelNameLengthLimit: 0
    labelValueLengthLimit: 0
    proxyUrl: ""
    scheme: http
    insecureSkipVerify: false
    serverName: ""
    caFile: ""
    certFile: ""
    keyFile: ""
    port: http-metrics

    jobLabel: jobLabel
    selector: {}
    #  matchLabels:
    #    component: etcd

    metricRelabelings: []
    # - action: keep
    #   regex: 'kube_(daemonset|deployment|pod|namespace|node|statefulset).+'
    #   sourceLabels: [__name__]

    relabelings: []
    # - sourceLabels: [__meta_kubernetes_pod_node_name]
    #   separator: ;
    #   regex: ^(.*)$
    #   targetLabel: nodename
    #   replacement: $1
    #   action: replace

    additionalLabels: {}
    #  foo: bar

kubeScheduler:
  enabled: true
  endpoints: # ips of servers
    - 192.168.40.110

  service:
    enabled: true
    port: null
    targetPort: null
    ipDualStack:
      enabled: false
      ipFamilies: ["IPv6", "IPv4"]
      ipFamilyPolicy: "PreferDualStack"

  serviceMonitor:
    enabled: true
    interval: ""
    sampleLimit: 0
    targetLimit: 0
    labelLimit: 0
    labelNameLengthLimit: 0
    labelValueLengthLimit: 0
    proxyUrl: ""
    https: null
    port: http-metrics

    jobLabel: jobLabel
    selector: {}
    #  matchLabels:
    #    component: kube-scheduler

    insecureSkipVerify: null

    serverName: null
    metricRelabelings: []
    # - action: keep
    #   regex: 'kube_(daemonset|deployment|pod|namespace|node|statefulset).+'
    #   sourceLabels: [__name__]

    relabelings: []
    # - sourceLabels: [__meta_kubernetes_pod_node_name]
    #   separator: ;
    #   regex: ^(.*)$
    #   targetLabel: nodename
    #   replacement: $1
    #   action: replace

    additionalLabels: {}
    #  foo: bar

kubeProxy:
  enabled: true
  endpoints: # ips of servers
    - 192.168.40.110

  service:
    enabled: true
    port: 10249
    targetPort: 10249
    ipDualStack:
      enabled: false
      ipFamilies: ["IPv6", "IPv4"]
      ipFamilyPolicy: "PreferDualStack"

  serviceMonitor:
    enabled: true
    interval: ""
    sampleLimit: 0
    targetLimit: 0
    labelLimit: 0
    labelNameLengthLimit: 0
    labelValueLengthLimit: 0
    proxyUrl: ""
    port: http-metrics

    jobLabel: jobLabel
    selector: {}
    #  matchLabels:
    #    k8s-app: kube-proxy

    https: false

    metricRelabelings: []
    # - action: keep
    #   regex: 'kube_(daemonset|deployment|pod|namespace|node|statefulset).+'
    #   sourceLabels: [__name__]

    relabelings: []
    # - action: keep
    #   regex: 'kube_(daemonset|deployment|pod|namespace|node|statefulset).+'
    #   sourceLabels: [__name__]

    additionalLabels: {}
    #  foo: bar

kubeStateMetrics:
  enabled: true

kube-state-metrics:
  fullnameOverride: kube-state-metrics
  namespaceOverride: ""
  selfMonitor:
    enabled: true

  rbac:
    create: true
  releaseLabel: true

  prometheus:
    monitor:
      enabled: true
      interval: ""
      sampleLimit: 0
      targetLimit: 0
      labelLimit: 0
      labelNameLengthLimit: 0
      labelValueLengthLimit: 0
      scrapeTimeout: ""
      proxyUrl: ""
      honorLabels: true
      metricRelabelings: []
      # - action: keep
      #   regex: 'kube_(daemonset|deployment|pod|namespace|node|statefulset).+'
      #   sourceLabels: [__name__]
      relabelings:
        - action: replace
          regex: (.*)
          replacement: $1
          sourceLabels:
            - __meta_kubernetes_pod_node_name
          targetLabel: kubernetes_node

nodeExporter:
  enabled: true
  serviceMonitor:
    relabelings:
      - action: replace
        regex: (.*)
        replacement: $1
        sourceLabels:
          - __meta_kubernetes_pod_node_name
        targetLabel: kubernetes_node

  forceDeployDashboards: false

prometheus-node-exporter:
  fullnameOverride: node-exporter
  namespaceOverride: ""
  podLabels:
    jobLabel: node-exporter
  releaseLabel: true
  extraArgs:
    - --collector.filesystem.mount-points-exclude=^/(dev|proc|sys|var/lib/docker/.+|var/lib/kubelet/.+)($|/)
    - --collector.filesystem.fs-types-exclude=^(autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tracefs)$
  service:
    portName: http-metrics

  prometheus:
    monitor:
      enabled: true
      jobLabel: jobLabel
      interval: ""
      sampleLimit: 0
      targetLimit: 0
      labelLimit: 0
      labelNameLengthLimit: 0
      labelValueLengthLimit: 0
      scrapeTimeout: ""
      proxyUrl: ""
      metricRelabelings: []
      # - sourceLabels: [__name__]
      #   separator: ;
      #   regex: ^node_mountstats_nfs_(event|operations|transport)_.+
      #   replacement: $1
      #   action: drop
      relabelings:
        - action: replace
          regex: (.*)
          replacement: $1
          sourceLabels:
            - __meta_kubernetes_pod_node_name
          targetLabel: kubernetes_node

  rbac:
    pspEnabled: false

prometheusOperator:
  enabled: true

  prometheusConfigReloader:
    resources:
      requests:
        cpu: 200m
        memory: 50Mi
      limits:
        memory: 100Mi

  fullnameOverride: ""
  revisionHistoryLimit: 3
  strategy: {}

  tls:
    enabled: true
    tlsMinVersion: VersionTLS13
    internalPort: 10250

  admissionWebhooks:
    failurePolicy: ""
    timeoutSeconds: 10
    enabled: true
    caBundle: ""
    annotations: {}

    namespaceSelector: {}
    objectSelector: {}

    mutatingWebhookConfiguration:
      annotations: {}
      #   argocd.argoproj.io/hook: PreSync

    validatingWebhookConfiguration:
      annotations: {}
      #   argocd.argoproj.io/hook: PreSync

    deployment:
      enabled: false
      replicas: 1
      strategy: {}

      podDisruptionBudget: {}
      revisionHistoryLimit: 10

      tls:
        enabled: true
        tlsMinVersion: VersionTLS13
        internalPort: 10250

      serviceAccount:
        automountServiceAccountToken: false
        create: true
        name: ""

      service:
        annotations: {}
        labels: {}
        clusterIP: ""
        ipDualStack:
          enabled: false
          ipFamilies: ["IPv6", "IPv4"]
          ipFamilyPolicy: "PreferDualStack"

        nodePort: 31080
        nodePortTls: 31443
        additionalPorts: []
        loadBalancerIP: ""
        loadBalancerSourceRanges: []
        externalTrafficPolicy: Cluster
        type: ClusterIP
        externalIPs: []
      labels: {}
      annotations: {}
      podLabels: {}
      podAnnotations: {}

      livenessProbe:
        enabled: true
        failureThreshold: 3
        initialDelaySeconds: 30
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1

      readinessProbe:
        enabled: true
        failureThreshold: 3
        initialDelaySeconds: 5
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1

      resources: {}
      # limits:
      #   cpu: 200m
      #   memory: 200Mi
      # requests:
      #   cpu: 100m
      #   memory: 100Mi

      hostNetwork: false
      nodeSelector:
        kubernetes.io/hostname: dev-k3s-master-0
      tolerations: []

      affinity: {}
      dnsConfig: {}
      securityContext:
        fsGroup: 65534
        runAsGroup: 65534
        runAsNonRoot: true
        runAsUser: 65534
        seccompProfile:
          type: RuntimeDefault

      containerSecurityContext:
        allowPrivilegeEscalation: false
        readOnlyRootFilesystem: true
        capabilities:
          drop:
            - ALL

      automountServiceAccountToken: true

    patch:
      enabled: true
      resources: {}
      priorityClassName: ""
      ttlSecondsAfterFinished: 60
      annotations: {}
      podAnnotations: {}
      nodeSelector:
        kubernetes.io/hostname: dev-k3s-master-0
      affinity: {}
      tolerations: []
      securityContext:
        runAsGroup: 2000
        runAsNonRoot: true
        runAsUser: 2000
        seccompProfile:
          type: RuntimeDefault

      serviceAccount:
        create: true
        automountServiceAccountToken: true

    createSecretJob:
      securityContext:
        allowPrivilegeEscalation: false
        readOnlyRootFilesystem: true
        capabilities:
          drop:
          - ALL

    patchWebhookJob:
      securityContext:
        allowPrivilegeEscalation: false
        readOnlyRootFilesystem: true
        capabilities:
          drop:
          - ALL

    certManager:
      enabled: false
      # self-signed root certificate
      rootCert:
        duration: ""  # default to be 5y
      admissionCert:
        duration: ""  # default to be 1y

  namespaces: {}
  denyNamespaces: []
  alertmanagerInstanceNamespaces: []
  alertmanagerConfigNamespaces: []
  prometheusInstanceNamespaces: []
  thanosRulerInstanceNamespaces: []
  networkPolicy:
    enabled: false
    flavor: kubernetes
  serviceAccount:
    create: true
    name: ""
    automountServiceAccountToken: true

  service:
    annotations: {}
    labels: {}
    clusterIP: ""
    ipDualStack:
      enabled: false
      ipFamilies: ["IPv6", "IPv4"]
      ipFamilyPolicy: "PreferDualStack"

    nodePort: 30080
    nodePortTls: 30443
    additionalPorts: []
    loadBalancerIP: ""
    loadBalancerSourceRanges: []
    externalTrafficPolicy: Cluster
    type: ClusterIP
    externalIPs: []

  labels: {}
  annotations: {}
  podLabels: {}
  podAnnotations: {}
  kubeletService:
    enabled: true
    namespace: kube-system
    selector: ""
    name: ""

  serviceMonitor:
    selfMonitor: true
    additionalLabels: {}
    interval: ""
    sampleLimit: 0
    targetLimit: 0
    labelLimit: 0
    labelNameLengthLimit: 0
    labelValueLengthLimit: 0
    scrapeTimeout: ""
    metricRelabelings: []
    # - action: keep
    #   regex: 'kube_(daemonset|deployment|pod|namespace|node|statefulset).+'
    #   sourceLabels: [__name__]

    relabelings: []
    # - sourceLabels: [__meta_kubernetes_pod_node_name]
    #   separator: ;
    #   regex: ^(.*)$
    #   targetLabel: nodename
    #   replacement: $1
    #   action: replace

  resources: {}
  # limits:
  #   cpu: 200m
  #   memory: 200Mi
  # requests:
  #   cpu: 100m
  #   memory: 100Mi

  env:
    GOGC: "30"

  hostNetwork: false
  nodeSelector:
    kubernetes.io/hostname: dev-k3s-master-0
  tolerations: []
  affinity: {}
  dnsConfig: {}
    # nameservers:
    #   - 1.2.3.4
    # searches:
    #   - ns1.svc.cluster-domain.example
    #   - my.dns.search.suffix
    # options:
    #   - name: ndots
    #     value: "2"
  #   - name: edns0
  securityContext:
    fsGroup: 65534
    runAsGroup: 65534
    runAsNonRoot: true
    runAsUser: 65534
    seccompProfile:
      type: RuntimeDefault

  ## Container-specific security context configuration
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
  ##
  containerSecurityContext:
    allowPrivilegeEscalation: false
    readOnlyRootFilesystem: true
    capabilities:
      drop:
      - ALL

  # Enable vertical pod autoscaler support for prometheus-operator
  verticalPodAutoscaler:
    enabled: false

    # Recommender responsible for generating recommendation for the object.
    # List should be empty (then the default recommender will generate the recommendation)
    # or contain exactly one recommender.
    # recommenders:
    # - name: custom-recommender-performance

    # List of resources that the vertical pod autoscaler can control. Defaults to cpu and memory
    controlledResources: []
    # Specifies which resource values should be controlled: RequestsOnly or RequestsAndLimits.
    # controlledValues: RequestsAndLimits

    # Define the max allowed resources for the pod
    maxAllowed: {}
    # cpu: 200m
    # memory: 100Mi
    # Define the min allowed resources for the pod
    minAllowed: {}
    # cpu: 200m
    # memory: 100Mi

    updatePolicy:
      # Specifies minimal number of replicas which need to be alive for VPA Updater to attempt pod eviction
      # minReplicas: 1
      # Specifies whether recommended updates are applied when a Pod is started and whether recommended updates
      # are applied during the life of a Pod. Possible values are "Off", "Initial", "Recreate", and "Auto".
      updateMode: Auto


  prometheusConfigReloader:
    # image:
    #   registry: quay.io
    #   repository: prometheus-operator/prometheus-config-reloader
    #   # if not set appVersion field from Chart.yaml is used
    #   tag: ""
    #   sha: ""

    # add prometheus config reloader liveness and readiness probe. Default: false
    enableProbe: false

    # resource config for prometheusConfigReloader
    resources: {}
      # requests:
      #   cpu: 200m
      #   memory: 50Mi
      # limits:
      #   cpu: 200m
      #   memory: 50Mi

  ## Thanos side-car image when configured
  ##
  # thanosImage:
  #   registry: quay.io
  #   repository: thanos/thanos
  #   tag: v0.35.1
  #   sha: ""

  ## Set a Label Selector to filter watched prometheus and prometheusAgent
  ##
  prometheusInstanceSelector: ""

  ## Set a Label Selector to filter watched alertmanager
  ##
  alertmanagerInstanceSelector: ""

  ## Set a Label Selector to filter watched thanosRuler
  thanosRulerInstanceSelector: ""

  ## Set a Field Selector to filter watched secrets
  ##
  secretFieldSelector: "type!=kubernetes.io/dockercfg,type!=kubernetes.io/service-account-token,type!=helm.sh/release.v1"

  ## If false then the user will opt out of automounting API credentials.
  ##
  automountServiceAccountToken: true

  ## Additional volumes
  ##
  extraVolumes: []

  ## Additional volume mounts
  ##
  extraVolumeMounts: []

## Deploy a Prometheus instance
##
prometheus:
  enabled: true
  prometheusSpec:
    replicas: 1
    replicaExternalLabelName: "replica"
    ruleSelectorNilUsesHelmValues: false
    serviceMonitorSelectorNilUsesHelmValues: false
    podMonitorSelectorNilUsesHelmValues: false
    probeSelectorNilUsesHelmValues: false
    retention: 6h
    enableAdminAPI: true
    walCompression: true
    scrapeInterval: 30s
    evaluationInterval: 30s

  agentMode: false
  annotations: {}
  networkPolicy:
    enabled: false
    flavor: kubernetes
  serviceAccount:
    create: true
    name: ""
    annotations: {}
    automountServiceAccountToken: true

  thanosService:
    enabled: false
    annotations: {}
    labels: {}
    externalTrafficPolicy: Cluster
    type: ClusterIP
    ipDualStack:
      enabled: false
      ipFamilies: ["IPv6", "IPv4"]
      ipFamilyPolicy: "PreferDualStack"
    portName: grpc
    port: 10901
    targetPort: "grpc"
    httpPortName: http
    httpPort: 10902
    targetHttpPort: "http"
    clusterIP: "None"
    nodePort: 30901
    httpNodePort: 30902

  thanosServiceMonitor:
    enabled: false
    interval: ""
    additionalLabels: {}
    scheme: ""
    tlsConfig: {}
    bearerTokenFile:
    metricRelabelings: []
    relabelings: []
  thanosServiceExternal:
    enabled: false
    annotations: {}
    labels: {}
    loadBalancerIP: ""
    loadBalancerSourceRanges: []
    portName: grpc
    port: 10901
    targetPort: "grpc"
    httpPortName: http
    httpPort: 10902
    targetHttpPort: "http"
    externalTrafficPolicy: Cluster
    type: LoadBalancer
    nodePort: 30901
    httpNodePort: 30902
  service:
    annotations: {}
    labels: {}
    clusterIP: ""
    ipDualStack:
      enabled: false
      ipFamilies: ["IPv6", "IPv4"]
      ipFamilyPolicy: "PreferDualStack"

    ## Port for Prometheus Service to listen on
    ##
    port: 9090

    ## To be used with a proxy extraContainer port
    targetPort: 9090

    ## Port for Prometheus Reloader to listen on
    ##
    reloaderWebPort: 8080

    ## List of IP addresses at which the Prometheus server service is available
    ## Ref: https://kubernetes.io/docs/user-guide/services/#external-ips
    ##
    externalIPs: []

    ## Port to expose on each node
    ## Only used if service.type is 'NodePort'
    ##
    nodePort: 30090

    ## Loadbalancer IP
    ## Only use if service.type is "LoadBalancer"
    loadBalancerIP: ""
    loadBalancerSourceRanges: []

    ## Denotes if this Service desires to route external traffic to node-local or cluster-wide endpoints
    ##
    externalTrafficPolicy: Cluster

    ## Service type
    ##
    type: ClusterIP

    ## Additional ports to open for Prometheus service
    ##
    additionalPorts: []
    # additionalPorts:
    # - name: oauth-proxy
    #   port: 8081
    #   targetPort: 8081
    # - name: oauth-metrics
    #   port: 8082
    #   targetPort: 8082

    ## Consider that all endpoints are considered "ready" even if the Pods themselves are not
    ## Ref: https://kubernetes.io/docs/reference/kubernetes-api/service-resources/service-v1/#ServiceSpec
    publishNotReadyAddresses: false

    ## If you want to make sure that connections from a particular client are passed to the same Pod each time
    ## Accepts 'ClientIP' or 'None'
    ##
    sessionAffinity: None

    ## If you want to modify the ClientIP sessionAffinity timeout
    ## The value must be >0 && <=86400(for 1 day) if ServiceAffinity == "ClientIP"
    ##
    sessionAffinityConfig:
      clientIP:
        timeoutSeconds: 10800

  ## Configuration for creating a separate Service for each statefulset Prometheus replica
  ##
  servicePerReplica:
    enabled: false
    annotations: {}

    ## Port for Prometheus Service per replica to listen on
    ##
    port: 9090

    ## To be used with a proxy extraContainer port
    targetPort: 9090

    ## Port to expose on each node
    ## Only used if servicePerReplica.type is 'NodePort'
    ##
    nodePort: 30091

    ## Loadbalancer source IP ranges
    ## Only used if servicePerReplica.type is "LoadBalancer"
    loadBalancerSourceRanges: []

    ## Denotes if this Service desires to route external traffic to node-local or cluster-wide endpoints
    ##
    externalTrafficPolicy: Cluster

    ## Service type
    ##
    type: ClusterIP

    ## Service dual stack
    ##
    ipDualStack:
      enabled: false
      ipFamilies: ["IPv6", "IPv4"]
      ipFamilyPolicy: "PreferDualStack"

  ## Configure pod disruption budgets for Prometheus
  ## ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb/#specifying-a-poddisruptionbudget
  ##
  podDisruptionBudget:
    enabled: false
    minAvailable: 1
    maxUnavailable: ""

  # Ingress exposes thanos sidecar outside the cluster
  thanosIngress:
    enabled: false

    # For Kubernetes >= 1.18 you should specify the ingress-controller via the field ingressClassName
    # See https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/#specifying-the-class-of-an-ingress
    # ingressClassName: nginx

    annotations: {}
    labels: {}
    servicePort: 10901

    ## Port to expose on each node
    ## Only used if service.type is 'NodePort'
    ##
    nodePort: 30901

    ## Hosts must be provided if Ingress is enabled.
    ##
    hosts: []
      # - thanos-gateway.domain.com

    ## Paths to use for ingress rules
    ##
    paths: []
    # - /

    ## For Kubernetes >= 1.18 you should specify the pathType (determines how Ingress paths should be matched)
    ## See https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/#better-path-matching-with-path-types
    # pathType: ImplementationSpecific

    ## TLS configuration for Thanos Ingress
    ## Secret must be manually created in the namespace
    ##
    tls: []
    # - secretName: thanos-gateway-tls
    #   hosts:
    #   - thanos-gateway.domain.com
    #

  ## ExtraSecret can be used to store various data in an extra secret
  ## (use it for example to store hashed basic auth credentials)
  extraSecret:
    ## if not set, name will be auto generated
    # name: ""
    annotations: {}
    data: {}
  #   auth: |
  #     foo:$apr1$OFG3Xybp$ckL0FHDAkoXYIlH9.cysT0
  #     someoneelse:$apr1$DMZX2Z4q$6SbQIfyuLQd.xmo/P0m2c.

  ingress:
    enabled: false

    # For Kubernetes >= 1.18 you should specify the ingress-controller via the field ingressClassName
    # See https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/#specifying-the-class-of-an-ingress
    # ingressClassName: nginx

    annotations: {}
    labels: {}

    ## Redirect ingress to an additional defined port on the service
    # servicePort: 8081

    ## Hostnames.
    ## Must be provided if Ingress is enabled.
    ##
    # hosts:
    #   - prometheus.domain.com
    hosts: []

    ## Paths to use for ingress rules - one path should match the prometheusSpec.routePrefix
    ##
    paths: []
    # - /

    ## For Kubernetes >= 1.18 you should specify the pathType (determines how Ingress paths should be matched)
    ## See https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/#better-path-matching-with-path-types
    # pathType: ImplementationSpecific

    ## TLS configuration for Prometheus Ingress
    ## Secret must be manually created in the namespace
    ##
    tls: []
      # - secretName: prometheus-general-tls
      #   hosts:
      #     - prometheus.example.com

  ## Configuration for creating an Ingress that will map to each Prometheus replica service
  ## prometheus.servicePerReplica must be enabled
  ##
  ingressPerReplica:
    enabled: false

    # For Kubernetes >= 1.18 you should specify the ingress-controller via the field ingressClassName
    # See https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/#specifying-the-class-of-an-ingress
    # ingressClassName: nginx

    annotations: {}
    labels: {}

    ## Final form of the hostname for each per replica ingress is
    ## {{ ingressPerReplica.hostPrefix }}-{{ $replicaNumber }}.{{ ingressPerReplica.hostDomain }}
    ##
    ## Prefix for the per replica ingress that will have `-$replicaNumber`
    ## appended to the end
    hostPrefix: ""
    ## Domain that will be used for the per replica ingress
    hostDomain: ""

    ## Paths to use for ingress rules
    ##
    paths: []
    # - /

    ## For Kubernetes >= 1.18 you should specify the pathType (determines how Ingress paths should be matched)
    ## See https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/#better-path-matching-with-path-types
    # pathType: ImplementationSpecific

    ## Secret name containing the TLS certificate for Prometheus per replica ingress
    ## Secret must be manually created in the namespace
    tlsSecretName: ""

    ## Separated secret for each per replica Ingress. Can be used together with cert-manager
    ##
    tlsSecretPerReplica:
      enabled: false
      ## Final form of the secret for each per replica ingress is
      ## {{ tlsSecretPerReplica.prefix }}-{{ $replicaNumber }}
      ##
      prefix: "prometheus"

  ## Configure additional options for default pod security policy for Prometheus
  ## ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/
  podSecurityPolicy:
    allowedCapabilities: []
    allowedHostPaths: []
    volumes: []

  serviceMonitor:
    selfMonitor: true
    interval: ""
    additionalLabels: {}
    sampleLimit: 0
    targetLimit: 0
    labelLimit: 0
    labelNameLengthLimit: 0
    labelValueLengthLimit: 0
    scheme: ""
    tlsConfig: {}
    bearerTokenFile:
    metricRelabelings: []
    relabelings: []
    additionalEndpoints: []
  prometheusSpec:
    persistentVolumeClaimRetentionPolicy:
      whenDeleted: Retain
      whenScaled: Retain

    ## If true, pass --storage.tsdb.max-block-duration=2h to prometheus. This is already done if using Thanos
    ##
    ## AutomountServiceAccountToken indicates whether a service account token should be automatically mounted in the pod,
    ## If the field isn’t set, the operator mounts the service account token by default.
    ## Warning: be aware that by default, Prometheus requires the service account token for Kubernetes service discovery,
    ## It is possible to use strategic merge patch to project the service account token into the ‘prometheus’ container.
    automountServiceAccountToken: true

    disableCompaction: false
    ## APIServerConfig
    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#apiserverconfig
    ##
    apiserverConfig: {}

    ## Allows setting additional arguments for the Prometheus container
    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#monitoring.coreos.com/v1.Prometheus
    additionalArgs: []

    ## Interval between consecutive scrapes.
    ## Defaults to 30s.
    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/release-0.44/pkg/prometheus/promcfg.go#L180-L183
    ##
    scrapeInterval: ""

    ## Number of seconds to wait for target to respond before erroring
    ##
    scrapeTimeout: ""

    ## List of scrape classes to expose to scraping objects such as
    ## PodMonitors, ServiceMonitors, Probes and ScrapeConfigs.
    ##
    scrapeClasses: []
    # - name: istio-mtls
    #   default: false
    #   tlsConfig:
    #     caFile: /etc/prometheus/secrets/istio.default/root-cert.pem
    #     certFile: /etc/prometheus/secrets/istio.default/cert-chain.pem

    ## Interval between consecutive evaluations.
    ##
    evaluationInterval: ""

    ## ListenLocal makes the Prometheus server listen on loopback, so that it does not bind against the Pod IP.
    ##
    listenLocal: false

    ## EnableAdminAPI enables Prometheus the administrative HTTP API which includes functionality such as deleting time series.
    ## This is disabled by default.
    ## ref: https://prometheus.io/docs/prometheus/latest/querying/api/#tsdb-admin-apis
    ##
    enableAdminAPI: false

    ## Sets version of Prometheus overriding the Prometheus version as derived
    ## from the image tag. Useful in cases where the tag does not follow semver v2.
    version: ""

    ## WebTLSConfig defines the TLS parameters for HTTPS
    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#webtlsconfig
    web: {}

    ## Exemplars related settings that are runtime reloadable.
    ## It requires to enable the exemplar storage feature to be effective.
    exemplars: ""
      ## Maximum number of exemplars stored in memory for all series.
      ## If not set, Prometheus uses its default value.
      ## A value of zero or less than zero disables the storage.
      # maxSize: 100000

    # EnableFeatures API enables access to Prometheus disabled features.
    # ref: https://prometheus.io/docs/prometheus/latest/disabled_features/
    enableFeatures: []
    # - exemplar-storage

    ## Image of Prometheus.
    ##
    # image:
    #   registry: quay.io
    #   repository: prometheus/prometheus
    #   tag: v2.53.1
    #   sha: ""

    ## Tolerations for use with node taints
    ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
    ##
    tolerations: []
    #  - key: "key"
    #    operator: "Equal"
    #    value: "value"
    #    effect: "NoSchedule"

    ## If specified, the pod's topology spread constraints.
    ## ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/
    ##
    topologySpreadConstraints: []
    # - maxSkew: 1
    #   topologyKey: topology.kubernetes.io/zone
    #   whenUnsatisfiable: DoNotSchedule
    #   labelSelector:
    #     matchLabels:
    #       app: prometheus

    ## Alertmanagers to which alerts will be sent
    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#alertmanagerendpoints
    ##
    ## Default configuration will connect to the alertmanager deployed as part of this release
    ##
    alertingEndpoints: []
    # - name: ""
    #   namespace: ""
    #   port: http
    #   scheme: http
    #   pathPrefix: ""
    #   tlsConfig: {}
    #   bearerTokenFile: ""
    #   apiVersion: v2

    ## External labels to add to any time series or alerts when communicating with external systems
    ##
    externalLabels: {}

    ## enable --web.enable-remote-write-receiver flag on prometheus-server
    ##
    enableRemoteWriteReceiver: false

    ## Name of the external label used to denote replica name
    ##
    replicaExternalLabelName: ""
    replicaExternalLabelNameClear: false
    prometheusExternalLabelName: ""
    prometheusExternalLabelNameClear: false
    externalUrl: ""
    nodeSelector:
      kubernetes.io/hostname: dev-k3s-master-0
    secrets: []
    configMaps: []
    query: {}
    ruleNamespaceSelector: {}
    ruleSelectorNilUsesHelmValues: true
    ruleSelector: {}
    serviceMonitorSelectorNilUsesHelmValues: true
    serviceMonitorSelector: {}
    serviceMonitorNamespaceSelector: {}
    podMonitorSelectorNilUsesHelmValues: true
    podMonitorSelector: {}
    podMonitorNamespaceSelector: {}
    probeSelectorNilUsesHelmValues: true
    probeSelector: {}
    probeNamespaceSelector: {}
    scrapeConfigSelectorNilUsesHelmValues: true
    scrapeConfigSelector:
      matchLabels:
        release: kube-prometheus-stack
    scrapeConfigNamespaceSelector: {}
    retention: 20d
    retentionSize: 20GB
    tsdb:
      outOfOrderTimeWindow: 0s
    walCompression: true
    paused: false
    replicas: 1
    shards: 1
    logLevel: info
    logFormat: logfmt
    routePrefix: /
    podMetadata: {}
    podAntiAffinity: ""
    podAntiAffinityTopologyKey: kubernetes.io/hostname
    affinity: {}
    remoteRead: []
    additionalRemoteRead: []
    remoteWrite: []
    additionalRemoteWrite: []
    remoteWriteDashboards: false
    resources: {}

    storageSpec:
      volumeClaimTemplate:
        spec:
          accessModes:
          - ReadWriteOnce
          storageClassName: longhorn-data
          resources:
            requests:
              storage: 20Gi
          volumeName: pv-kube-prometheus # must reference Persistent Volume

    ## Using tmpfs volume
    ##
    #  emptyDir:
    #    medium: Memory

    # Additional volumes on the output StatefulSet definition.
    volumes: []

    # Additional VolumeMounts on the output StatefulSet definition.
    volumeMounts: []
    additionalScrapeConfigs:
    - job_name: kube-etcd
      kubernetes_sd_configs:
        - role: node
      scheme: https
      tls_config:
        ca_file:   /etc/prometheus/secrets/etcd-client-cert/etcd-ca
        cert_file: /etc/prometheus/secrets/etcd-client-cert/etcd-client
        key_file:  /etc/prometheus/secrets/etcd-client-cert/etcd-client-key
      relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
      - source_labels: [__address__]
        action: replace
        targetLabel: __address__
        regex: ([^:;]+):(\d+)
        replacement: ${1}:2379
      - source_labels: [__meta_kubernetes_node_name]
        action: keep
        regex: .*mst.*
      - source_labels: [__meta_kubernetes_node_name]
        action: replace
        targetLabel: node
        regex: (.*)
        replacement: ${1}
      metric_relabel_configs:
      - regex: (kubernetes_io_hostname|failure_domain_beta_kubernetes_io_region|beta_kubernetes_io_os|beta_kubernetes_io_arch|beta_kubernetes_io_instance_type|failure_domain_beta_kubernetes_io_zone)
        action: labeldrop

    # additionalScrapeConfigs: |
    #  - job_name: "node-exporter"
    #    gce_sd_configs:
    #    {{range $zone := .Values.gcp_zones}}
    #    - project: "project1"
    #      zone: "{{$zone}}"
    #      port: 9100
    #    {{end}}
    #    relabel_configs:
    #    ...

    additionalScrapeConfigsSecret: {}
    additionalPrometheusSecretsAnnotations: {}
    additionalAlertManagerConfigs: []
    additionalAlertManagerConfigsSecret: {}
    additionalAlertRelabelConfigs: []
    additionalAlertRelabelConfigsSecret: {}
    securityContext:
      runAsGroup: 2000
      runAsNonRoot: true
      runAsUser: 1000
      fsGroup: 2000
      seccompProfile:
        type: RuntimeDefault
    priorityClassName: ""
    thanos: {}
    containers: []
    initContainers: []
    portName: "http-web"
    arbitraryFSAccessThroughSMs: false

    ## OverrideHonorLabels if set to true overrides all user configured honor_labels. If HonorLabels is set in ServiceMonitor
    ## or PodMonitor to true, this overrides honor_labels to false.
    overrideHonorLabels: false

    ## OverrideHonorTimestamps allows to globally enforce honoring timestamps in all scrape configs.
    overrideHonorTimestamps: false

    ## When ignoreNamespaceSelectors is set to true, namespaceSelector from all PodMonitor, ServiceMonitor and Probe objects will be ignored,
    ## they will only discover targets within the namespace of the PodMonitor, ServiceMonitor and Probe object,
    ## and servicemonitors will be installed in the default service namespace.
    ## Defaults to false.
    ignoreNamespaceSelectors: false

    ## EnforcedNamespaceLabel enforces adding a namespace label of origin for each alert and metric that is user created.
    ## The label value will always be the namespace of the object that is being created.
    ## Disabled by default
    enforcedNamespaceLabel: ""

    ## PrometheusRulesExcludedFromEnforce - list of prometheus rules to be excluded from enforcing of adding namespace labels.
    ## Works only if enforcedNamespaceLabel set to true. Make sure both ruleNamespace and ruleName are set for each pair
    ## Deprecated, use `excludedFromEnforcement` instead
    prometheusRulesExcludedFromEnforce: []

    ## ExcludedFromEnforcement - list of object references to PodMonitor, ServiceMonitor, Probe and PrometheusRule objects
    ## to be excluded from enforcing a namespace label of origin.
    ## Works only if enforcedNamespaceLabel set to true.
    ## See https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#objectreference
    excludedFromEnforcement: []

    ## QueryLogFile specifies the file to which PromQL queries are logged. Note that this location must be writable,
    ## and can be persisted using an attached volume. Alternatively, the location can be set to a stdout location such
    ## as /dev/stdout to log querie information to the default Prometheus log stream. This is only available in versions
    ## of Prometheus >= 2.16.0. For more details, see the Prometheus docs (https://prometheus.io/docs/guides/query-log/)
    queryLogFile: false

    # Use to set global sample_limit for Prometheus. This act as default SampleLimit for ServiceMonitor or/and PodMonitor.
    # Set to 'false' to disable global sample_limit. or set to a number to override the default value.
    sampleLimit: false

    # EnforcedKeepDroppedTargetsLimit defines on the number of targets dropped by relabeling that will be kept in memory.
    # The value overrides any spec.keepDroppedTargets set by ServiceMonitor, PodMonitor, Probe objects unless spec.keepDroppedTargets
    # is greater than zero and less than spec.enforcedKeepDroppedTargets. 0 means no limit.
    enforcedKeepDroppedTargets: 0

    ## EnforcedSampleLimit defines global limit on number of scraped samples that will be accepted. This overrides any SampleLimit
    ## set per ServiceMonitor or/and PodMonitor. It is meant to be used by admins to enforce the SampleLimit to keep overall
    ## number of samples/series under the desired limit. Note that if SampleLimit is lower that value will be taken instead.
    enforcedSampleLimit: false

    ## EnforcedTargetLimit defines a global limit on the number of scraped targets. This overrides any TargetLimit set
    ## per ServiceMonitor or/and PodMonitor. It is meant to be used by admins to enforce the TargetLimit to keep the overall
    ## number of targets under the desired limit. Note that if TargetLimit is lower, that value will be taken instead, except
    ## if either value is zero, in which case the non-zero value will be used. If both values are zero, no limit is enforced.
    enforcedTargetLimit: false


    ## Per-scrape limit on number of labels that will be accepted for a sample. If more than this number of labels are present
    ## post metric-relabeling, the entire scrape will be treated as failed. 0 means no limit. Only valid in Prometheus versions
    ## 2.27.0 and newer.
    enforcedLabelLimit: false

    ## Per-scrape limit on length of labels name that will be accepted for a sample. If a label name is longer than this number
    ## post metric-relabeling, the entire scrape will be treated as failed. 0 means no limit. Only valid in Prometheus versions
    ## 2.27.0 and newer.
    enforcedLabelNameLengthLimit: false

    ## Per-scrape limit on length of labels value that will be accepted for a sample. If a label value is longer than this
    ## number post metric-relabeling, the entire scrape will be treated as failed. 0 means no limit. Only valid in Prometheus
    ## versions 2.27.0 and newer.
    enforcedLabelValueLengthLimit: false

    ## AllowOverlappingBlocks enables vertical compaction and vertical query merge in Prometheus. This is still experimental
    ## in Prometheus so it may change in any upcoming release.
    allowOverlappingBlocks: false

    ## Minimum number of seconds for which a newly created pod should be ready without any of its container crashing for it to
    ## be considered available. Defaults to 0 (pod will be considered available as soon as it is ready).
    minReadySeconds: 0

    # Required for use in managed kubernetes clusters (such as AWS EKS) with custom CNI (such as calico),
    # because control-plane managed by AWS cannot communicate with pods' IP CIDR and admission webhooks are not working
    # Use the host's network namespace if true. Make sure to understand the security implications if you want to enable it.
    # When hostNetwork is enabled, this will set dnsPolicy to ClusterFirstWithHostNet automatically.
    hostNetwork: false

    # HostAlias holds the mapping between IP and hostnames that will be injected
    # as an entry in the pod’s hosts file.
    hostAliases: []
    #  - ip: 10.10.0.100
    #    hostnames:
    #      - a1.app.local
    #      - b1.app.local

    ## TracingConfig configures tracing in Prometheus.
    ## See https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#prometheustracingconfig
    tracingConfig: {}

    ## Additional configuration which is not covered by the properties above. (passed through tpl)
    additionalConfig: {}

    ## Additional configuration which is not covered by the properties above.
    ## Useful, if you need advanced templating inside alertmanagerSpec.
    ## Otherwise, use prometheus.prometheusSpec.additionalConfig (passed through tpl)
    additionalConfigString: ""

    ## Defines the maximum time that the `prometheus` container's startup probe
    ## will wait before being considered failed. The startup probe will return
    ## success after the WAL replay is complete. If set, the value should be
    ## greater than 60 (seconds). Otherwise it will be equal to 900 seconds (15
    ## minutes).
    maximumStartupDurationSeconds: 0

  additionalRulesForClusterRole: []
  #  - apiGroups: [ "" ]
  #    resources:
  #      - nodes/proxy
  #    verbs: [ "get", "list", "watch" ]

  additionalServiceMonitors: []
  additionalPodMonitors: []

thanosRuler:
  enabled: false
  annotations: {}
  serviceAccount:
    create: true
    name: ""
    annotations: {}

  podDisruptionBudget:
    enabled: false
    minAvailable: 1
    maxUnavailable: ""

  ingress:
    enabled: false
    annotations: {}
    labels: {}
    hosts: []
      # - thanosruler.domain.com
    paths: []
    # - /
    tls: []

  service:
    annotations: {}
    labels: {}
    clusterIP: ""
    ipDualStack:
      enabled: false
      ipFamilies: ["IPv6", "IPv4"]
      ipFamilyPolicy: "PreferDualStack"

    port: 10902
    targetPort: 10902
    nodePort: 30905
    additionalPorts: []
    externalIPs: []
    loadBalancerIP: ""
    loadBalancerSourceRanges: []
    externalTrafficPolicy: Cluster
    type: ClusterIP

  serviceMonitor:
    selfMonitor: true
    interval: ""
    additionalLabels: {}
    sampleLimit: 0
    targetLimit: 0
    labelLimit: 0
    labelNameLengthLimit: 0
    labelValueLengthLimit: 0
    proxyUrl: ""
    scheme: ""
    tlsConfig: {}
    bearerTokenFile:
    metricRelabelings: []
    relabelings: []
    additionalEndpoints: []

  thanosRulerSpec:
    podMetadata: {}
    ruleNamespaceSelector: {}
    ruleSelectorNilUsesHelmValues: true
    ruleSelector: {}
    logFormat: logfmt
    logLevel: info
    replicas: 1
    retention: 24h
    evaluationInterval: ""
    storage: {}
    alertmanagersConfig:
      existingSecret: {}
      secret: {}
    externalPrefix:
    externalPrefixNilUsesHelmValues: true
    routePrefix: /
    objectStorageConfig:
      existingSecret: {}
      secret: {}
    alertDropLabels: []
    queryEndpoints: []
    queryConfig:
      existingSecret: {}
      secret: {}
    labels: {}
    paused: false
    additionalArgs: []
    nodeSelector:
      kubernetes.io/hostname: dev-k3s-master-0
    resources: {}
    podAntiAffinity: ""
    podAntiAffinityTopologyKey: kubernetes.io/hostname
    affinity: {}
    tolerations: []
    topologySpreadConstraints: []
    securityContext:
      runAsGroup: 2000
      runAsNonRoot: true
      runAsUser: 1000
      fsGroup: 2000
      seccompProfile:
        type: RuntimeDefault
    listenLocal: false
    containers: []
    volumes: []
    volumeMounts: []
    initContainers: []
    priorityClassName: ""
    portName: "web"
    additionalConfig: {}
    additionalConfigString: ""

  extraSecret:
    annotations: {}
    data: {}

cleanPrometheusOperatorObjectNames: false
extraManifests: []

